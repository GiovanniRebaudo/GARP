q()
(0.1*0.6)/(0.1*0.6+0.9*0.2)
max(0.5,1-0.05)
tinytex::install_tinytex()
plot(lm(mpg ~ horsepower, data = Auto))
library(ISLR2)
set.seed(1)
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,
subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,
subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
set.seed(2)
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, subset = train)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,
subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,
subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
coef(glm.fit)
lm.fit <- lm(mpg ~ horsepower, data = Auto)
coef(lm.fit)
library(boot)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
cv.err <- cv.glm(Auto, glm.fit)
cv.err$delta
cv.error <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10 <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error.10
alpha.fn <- function(data, index) {
X <- data$X[index]
Y <- data$Y[index]
(var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))
}
alpha.fn(Portfolio, 1:100)
set.seed(7)
alpha.fn(Portfolio, sample(100, 100, replace = T))
boot(Portfolio, alpha.fn, R = 1000)
boot.fn <- function(data, index)
coef(lm(mpg ~ horsepower, data = data, subset = index))
boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
boot.fn(Auto, sample(392, 392, replace = T))
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data = Auto))$coef
plot(lm(mpg ~ horsepower, data = Auto))
plot(mpg ~ horsepower)
plot(lm(mpg ~ horsepower, data = Auto))
boot.fn <- function(data, index)
coef(
lm(mpg ~ horsepower + I(horsepower^2),
data = data, subset = index)
)
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
par(mfrow=c(2,2))
plot(mpg ~ horsepower)
library(ISLR2)
set.seed(1)
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,
subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,
subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
set.seed(2)
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, subset = train)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,
subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,
subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
coef(glm.fit)
lm.fit <- lm(mpg ~ horsepower, data = Auto)
coef(lm.fit)
library(boot)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
cv.err <- cv.glm(Auto, glm.fit)
cv.err$delta
cv.error <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10 <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error.10
alpha.fn <- function(data, index) {
X <- data$X[index]
Y <- data$Y[index]
(var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))
}
alpha.fn(Portfolio, 1:100)
set.seed(7)
alpha.fn(Portfolio, sample(100, 100, replace = T))
boot(Portfolio, alpha.fn, R = 1000)
boot.fn <- function(data, index)
coef(lm(mpg ~ horsepower, data = data, subset = index))
boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
boot.fn(Auto, sample(392, 392, replace = T))
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data = Auto))$coef
par(mfrow=c(2,2))
plot(mpg ~ horsepower)
plot(lm(mpg ~ horsepower, data = Auto))
boot.fn <- function(data, index)
coef(
lm(mpg ~ horsepower + I(horsepower^2),
data = data, subset = index)
)
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
plot(mpg ~ horsepower)
```{r chunk19}
plot(mpg ~ horsepower)
par(mfrow=c(2,2))
plot(lm(mpg ~ horsepower, data = Auto))
###
boot.fn <- function(data, index)
coef(lm(mpg ~ horsepower, data = data, subset = index))
boot.fn(Auto, 1:392)
###
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
boot.fn(Auto, sample(392, 392, replace = T))
###
boot(Auto, boot.fn, 1000)
###
summary(lm(mpg ~ horsepower, data = Auto))$coef
###
boot.fn <- function(data, index)
coef(
lm(mpg ~ horsepower + I(horsepower^2),
data = data, subset = index)
)
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
###
# OLS is based on restrictive (in this case) assumptions
plot(mpg ~ horsepower)
par(mfrow=c(2,2))
plot(lm(mpg ~ horsepower, data = Auto))
tlmgr_install(
pkgs = "mathtools.sty"
)
tinytex::parse_install(
text = "! LaTeX Error: File `mathtools.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `ulem.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `dutchcal.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `arydshln.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `placeins.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `tablefootnote.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `xifthen.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `ifmtarg.sty' not found."
)
tinytex::parse_install(
text = "! Package pdftex.def Error: File `Image/Boxplot_DE.png' not found: using draft setting."
)
tinytex::parse_install(
text = "! LaTeX Error: File `Image/Mice_Data' not found."
)
install.packages("igraph")
tinytex::parse_install(
text = "! LaTeX Error: File `size9.clo' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `relsize.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `soul.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `beamerthememetropolis.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `pgfopts.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `type1cm.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `algorithm.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `algpseudocode.sty' not found."
)
tinytex::parse_install(
text = "LaTeX Font Warning: Font shape `U/rsfs/m/n' in size <8.5> not available"
)
tinytex::parse_install(
text = "! LaTeX Font Warning: Font shape `U/rsfs/m/n' in size <8.5> not available"
)
## Clear the workspace
rm(list = ls())
library(rstudioapi)
## Clear the workspace
rm(list = ls())
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("functions.R")
library("TruncatedNormal")
library("EPGLM")
## Clear the workspace
rm(list = ls())
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("functions.R")
library("TruncatedNormal")
library("EPGLM")
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix()
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(nc[1:c]))
b = sum(nc[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(nc[c+1]*dim, mu[c], sigma[c])
c_truth[a:b, 1] = rep(c, nc[c+1])
}
return(list(y = y$V1, c_truth = c_truth))
}
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
y           = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix()
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:c]))
b = sum(freq[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(freq[c+1]*dim, mu[c], sigma[c])
c_truth[a:b, 1] = rep(c, freq[c+1])
}
return(list(y = y$V1, c_truth = c_truth))
}
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
y           = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
y  = matrix()
Kn = length(freq)
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
freq  = freq_truth
dim   = J
mu    = mu_truth
sigma = sigma_truth
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:c]))
b = sum(freq[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(freq[c+1]*dim, mu[c], sigma[c])
c_truth[a:b, 1] = rep(c, freq[c+1])
}
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:c]))
b = sum(freq[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(freq[c+1]*dim, mu[c], sigma[c])
c_truth[a:b]  = c
}
return(list(y = y, c_truth = c_truth))
}
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
y           = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
data        = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
# Simulation study multivariate ------------------------------------------------------------
set.seed(0)
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
data        = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
y           = data$y - mean(data$y) # center the data
y           = scale(y)              # scale the data
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:(c-1)]))
b = sum(freq[1:c]) - 1
y[a:b, 1:dim] = rnorm(freq[c]*dim, mu[c], sigma[c])
c_truth[a:b]  = c
}
return(list(y = y, c_truth = c_truth))
}
data        = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:(c-1)]))
b = sum(freq[1:c]) - 1
y[a:b, 1:dim] = rnorm(freq[c]*dim, mu[c], sigma[c])
c_truth[a:b]  = c
}
return(list(y = y, c_truth = c_truth))
}
source("C:/Users/39339/Dropbox/GitHub/GARP/GARP_extra.R", echo=TRUE)
