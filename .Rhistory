}
cv.error
set.seed(17)
cv.error.10 <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error.10
alpha.fn <- function(data, index) {
X <- data$X[index]
Y <- data$Y[index]
(var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))
}
alpha.fn(Portfolio, 1:100)
set.seed(7)
alpha.fn(Portfolio, sample(100, 100, replace = T))
boot(Portfolio, alpha.fn, R = 1000)
boot.fn <- function(data, index)
coef(lm(mpg ~ horsepower, data = data, subset = index))
boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
boot.fn(Auto, sample(392, 392, replace = T))
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data = Auto))$coef
plot(lm(mpg ~ horsepower, data = Auto))
plot(mpg ~ horsepower)
plot(lm(mpg ~ horsepower, data = Auto))
boot.fn <- function(data, index)
coef(
lm(mpg ~ horsepower + I(horsepower^2),
data = data, subset = index)
)
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
par(mfrow=c(2,2))
plot(mpg ~ horsepower)
library(ISLR2)
set.seed(1)
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,
subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,
subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
set.seed(2)
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, subset = train)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,
subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,
subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
coef(glm.fit)
lm.fit <- lm(mpg ~ horsepower, data = Auto)
coef(lm.fit)
library(boot)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
cv.err <- cv.glm(Auto, glm.fit)
cv.err$delta
cv.error <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10 <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error.10
alpha.fn <- function(data, index) {
X <- data$X[index]
Y <- data$Y[index]
(var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))
}
alpha.fn(Portfolio, 1:100)
set.seed(7)
alpha.fn(Portfolio, sample(100, 100, replace = T))
boot(Portfolio, alpha.fn, R = 1000)
boot.fn <- function(data, index)
coef(lm(mpg ~ horsepower, data = data, subset = index))
boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
boot.fn(Auto, sample(392, 392, replace = T))
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data = Auto))$coef
par(mfrow=c(2,2))
plot(mpg ~ horsepower)
plot(lm(mpg ~ horsepower, data = Auto))
boot.fn <- function(data, index)
coef(
lm(mpg ~ horsepower + I(horsepower^2),
data = data, subset = index)
)
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
plot(mpg ~ horsepower)
```{r chunk19}
plot(mpg ~ horsepower)
par(mfrow=c(2,2))
plot(lm(mpg ~ horsepower, data = Auto))
###
boot.fn <- function(data, index)
coef(lm(mpg ~ horsepower, data = data, subset = index))
boot.fn(Auto, 1:392)
###
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
boot.fn(Auto, sample(392, 392, replace = T))
###
boot(Auto, boot.fn, 1000)
###
summary(lm(mpg ~ horsepower, data = Auto))$coef
###
boot.fn <- function(data, index)
coef(
lm(mpg ~ horsepower + I(horsepower^2),
data = data, subset = index)
)
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
###
# OLS is based on restrictive (in this case) assumptions
plot(mpg ~ horsepower)
par(mfrow=c(2,2))
plot(lm(mpg ~ horsepower, data = Auto))
tlmgr_install(
pkgs = "mathtools.sty"
)
tinytex::parse_install(
text = "! LaTeX Error: File `mathtools.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `ulem.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `dutchcal.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `arydshln.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `placeins.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `tablefootnote.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `xifthen.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `ifmtarg.sty' not found."
)
tinytex::parse_install(
text = "! Package pdftex.def Error: File `Image/Boxplot_DE.png' not found: using draft setting."
)
tinytex::parse_install(
text = "! LaTeX Error: File `Image/Mice_Data' not found."
)
install.packages("igraph")
tinytex::parse_install(
text = "! LaTeX Error: File `size9.clo' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `relsize.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `soul.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `beamerthememetropolis.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `pgfopts.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `type1cm.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `algorithm.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `algpseudocode.sty' not found."
)
tinytex::parse_install(
text = "LaTeX Font Warning: Font shape `U/rsfs/m/n' in size <8.5> not available"
)
tinytex::parse_install(
text = "! LaTeX Font Warning: Font shape `U/rsfs/m/n' in size <8.5> not available"
)
## Clear the workspace
rm(list = ls())
library(rstudioapi)
## Clear the workspace
rm(list = ls())
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("functions.R")
library("TruncatedNormal")
library("EPGLM")
## Clear the workspace
rm(list = ls())
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("functions.R")
library("TruncatedNormal")
library("EPGLM")
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix()
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(nc[1:c]))
b = sum(nc[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(nc[c+1]*dim, mu[c], sigma[c])
c_truth[a:b, 1] = rep(c, nc[c+1])
}
return(list(y = y$V1, c_truth = c_truth))
}
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
y           = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix()
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:c]))
b = sum(freq[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(freq[c+1]*dim, mu[c], sigma[c])
c_truth[a:b, 1] = rep(c, freq[c+1])
}
return(list(y = y$V1, c_truth = c_truth))
}
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
y           = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
y  = matrix()
Kn = length(freq)
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
freq  = freq_truth
dim   = J
mu    = mu_truth
sigma = sigma_truth
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:c]))
b = sum(freq[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(freq[c+1]*dim, mu[c], sigma[c])
c_truth[a:b, 1] = rep(c, freq[c+1])
}
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:c]))
b = sum(freq[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(freq[c+1]*dim, mu[c], sigma[c])
c_truth[a:b]  = c
}
return(list(y = y, c_truth = c_truth))
}
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
y           = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
data        = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
# Simulation study multivariate ------------------------------------------------------------
set.seed(0)
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
data        = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
y           = data$y - mean(data$y) # center the data
y           = scale(y)              # scale the data
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:(c-1)]))
b = sum(freq[1:c]) - 1
y[a:b, 1:dim] = rnorm(freq[c]*dim, mu[c], sigma[c])
c_truth[a:b]  = c
}
return(list(y = y, c_truth = c_truth))
}
data        = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:(c-1)]))
b = sum(freq[1:c]) - 1
y[a:b, 1:dim] = rnorm(freq[c]*dim, mu[c], sigma[c])
c_truth[a:b]  = c
}
return(list(y = y, c_truth = c_truth))
}
# Load relevant libraries, functions and data ----------------------------------
rm(list=ls())
# Set the working directory to the current folder
# Code to set the working directory to the current folder from RStudio
library(rstudioapi) # version 0.14
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(MASS)          # version 7.3-58.2
library(ggplot2)       # version 3.4.2
theme_set(theme_bw(base_size = 14))
library(viridis)       # version 0.6.2
library(salso)         # version 0.3.29
library(reshape2)      # version 1.4.4
library(Cairo)         # version 1.6-0
library(scales)        # version 1.2.1
library(plyr)          # version 1.8.8
library(mvtnorm)       # version 1.1-3
library(LaplacesDemon) # version 16.1.6
library(bayesm)        # version 3.1-5
library(mniw)          # version 1.0.1
library(xtable)        # version 1.8-4
# Load functions
source("GARP_fcts.R")
# Load data
y = get(load("./Data-and-Results/Data.RData"))
P = ncol(y)
N = nrow(y)
# If you want to save the plot
Save_Plot = TRUE
# Data scatter plot (Figure 1 in the main manuscript)
Plot_1 = pre_plot(y)
if(Save_Plot){
CairoPNG(filename = './Image/Mice_Data.png', width = 500, height = 400)}
Plot_1
if(Save_Plot){invisible(dev.off())}
# Gaussian edge contour plot
# (Figure S.1 in the supplementary materials)
Plot_S1 = edge_countorplot(vertices  = rbind(c(-2,-2), c(3,3)),
data.grid = expand.grid(X=seq(-3,4,length.out=800),
Y=seq(-3,4,length.out=800)))
if(Save_Plot){
CairoPNG(filename = './Image/Gauss_Edge_Countor.png', width=500, height=400)}
Plot_S1
if(Save_Plot){invisible(dev.off())}
# Run the MCMC -----------------------------------------------------------------
# GARP hyperparameters
# Random partition parameters
p_s       = 0.5 # change to p_v
gamma_GN  = 0.5
alpha_Dir = 0.5
## NIG hyperparameters
mu0       = colMeans(y)
kappa0    = 0.001
nu0       = 100
Lambda0   = diag(rep(15,P))
# MCMC quantities
Niter     = 10000
run_MCMC  = FALSE
if(run_MCMC){
# Set the seed for reproducibility
set.seed(123)
# pt1 = proc.time() # compute time
output = GARP_MCMC(data    = data,
mu0     = mu0,
kappa0  = kappa0,
nu0     = nu0,
Lambda0 = Lambda0,
p_s     = p_s,
Niter   = Niter,
Plot    = FALSE,
acc_p   = FALSE)
# pt2 = proc.time()
# pt2-pt1
# save(output, file="./Data-and-Results/output.RData")
} else {
load("./Data-and-Results/output.RData")
}
attach(output)
# Thinning
thin         = 2
burn.in      = Niter/2
seq_thin     = seq(from=burn.in, to=Niter, by=thin)
Niter_ps     = length(seq_thin)
# Assign cells to vertex/edge phases
p_s_i        = colMeans(stable_out[seq_thin,])
is_i_stable  = (p_s_i>0.5)
(N_S_map     = sum(is_i_stable))
(N_T_map     = N-N_S_map)
# Point estimate vertex-clustering
clust_VI_stable       = salso(cl_memb_all_out[seq_thin,is_i_stable], loss=VI())
uni_clust_data_stable = unique(clust_VI_stable)
# Number of vertex clusters
c_clust_data_stable       = length(uni_clust_data_stable)
# Frequencies of vertex clusters
freq_clust_VI_stable      = double(c_clust_data_stable)
for (i in 1:c_clust_data_stable){
uni_clust_stable        = uni_clust_data_stable[i]
freq_clust_VI_stable[i] = sum(clust_VI_stable==uni_clust_stable)
}
freq_clust_VI_stable
# Compute probability of co-clustering of cells assigned to vertices
dissimlar_stable = psm(cl_memb_all_out[seq_thin,is_i_stable])
# Posterior probabilities of co-clustering of obs assigned to vertices.
# (Figure 2b in the main manuscript)
Plot_2b = Plot_heat_vertex(dissimlar_stable = dissimlar_stable,
N_S_map          = N_S_map)
if(Save_Plot){
CairoPNG(filename = './Image/Prob_Coclus_obs_Mice_Data_Orange.png',
width = 500, height = 400)}
Plot_2b
if(Save_Plot){invisible(dev.off())}
# Edge assignments
if(run_MCMC){
# Set the seed for reproducibility
set.seed(123)
output_edge = GARP_Edge(y                   = y,
is_i_stable         = is_i_stable,
c_clust_data_stable = c_clust_data_stable,
kappa0              = kappa0,
nu0                 = nu0,
Lambda0             = Lambda0,
Niter               = Niter,
Plot                = TRUE)
# save(output_edge, file="./Data-and-Results/output_edge.RData")
} else {
load("./Data-and-Results/output_edge.RData")
}
attach(output_edge)
# Scatter-plot of the scRNA data with GARP point estimate.
# (Figure 2a in the main manuscript)
Plot_2a = Plot_result_GARP(y                   = y,
is_i_stable         = is_i_stable,
clust_VI_stable     = clust_VI_stable,
mu_stable_map       = mu_stable_map,
Map_k_edge          = Map_k_edge,
cl_memb_edge_out    = cl_memb_edge_out
)
if(Save_Plot){CairoPNG(filename = './Image/Inference_Scatter_Mice.png',
width = 500, height = 400)}
Plot_2a
if(Save_Plot){invisible(dev.off())}
# (Table 3 in the main manuscript)
Table_4_GARP = Freq_Kv(cl_samp=cl_memb_stable_out[seq_thin,])
