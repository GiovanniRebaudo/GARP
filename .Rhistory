q()
(0.1*0.6)/(0.1*0.6+0.9*0.2)
max(0.5,1-0.05)
tinytex::install_tinytex()
plot(lm(mpg ~ horsepower, data = Auto))
library(ISLR2)
set.seed(1)
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,
subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,
subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
set.seed(2)
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, subset = train)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,
subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,
subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
coef(glm.fit)
lm.fit <- lm(mpg ~ horsepower, data = Auto)
coef(lm.fit)
library(boot)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
cv.err <- cv.glm(Auto, glm.fit)
cv.err$delta
cv.error <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10 <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error.10
alpha.fn <- function(data, index) {
X <- data$X[index]
Y <- data$Y[index]
(var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))
}
alpha.fn(Portfolio, 1:100)
set.seed(7)
alpha.fn(Portfolio, sample(100, 100, replace = T))
boot(Portfolio, alpha.fn, R = 1000)
boot.fn <- function(data, index)
coef(lm(mpg ~ horsepower, data = data, subset = index))
boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
boot.fn(Auto, sample(392, 392, replace = T))
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data = Auto))$coef
plot(lm(mpg ~ horsepower, data = Auto))
plot(mpg ~ horsepower)
plot(lm(mpg ~ horsepower, data = Auto))
boot.fn <- function(data, index)
coef(
lm(mpg ~ horsepower + I(horsepower^2),
data = data, subset = index)
)
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
par(mfrow=c(2,2))
plot(mpg ~ horsepower)
library(ISLR2)
set.seed(1)
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,
subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,
subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
set.seed(2)
train <- sample(392, 196)
lm.fit <- lm(mpg ~ horsepower, subset = train)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,
subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,
subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
coef(glm.fit)
lm.fit <- lm(mpg ~ horsepower, data = Auto)
coef(lm.fit)
library(boot)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
cv.err <- cv.glm(Auto, glm.fit)
cv.err$delta
cv.error <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10 <- rep(0, 10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error.10
alpha.fn <- function(data, index) {
X <- data$X[index]
Y <- data$Y[index]
(var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))
}
alpha.fn(Portfolio, 1:100)
set.seed(7)
alpha.fn(Portfolio, sample(100, 100, replace = T))
boot(Portfolio, alpha.fn, R = 1000)
boot.fn <- function(data, index)
coef(lm(mpg ~ horsepower, data = data, subset = index))
boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
boot.fn(Auto, sample(392, 392, replace = T))
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data = Auto))$coef
par(mfrow=c(2,2))
plot(mpg ~ horsepower)
plot(lm(mpg ~ horsepower, data = Auto))
boot.fn <- function(data, index)
coef(
lm(mpg ~ horsepower + I(horsepower^2),
data = data, subset = index)
)
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
plot(mpg ~ horsepower)
```{r chunk19}
plot(mpg ~ horsepower)
par(mfrow=c(2,2))
plot(lm(mpg ~ horsepower, data = Auto))
###
boot.fn <- function(data, index)
coef(lm(mpg ~ horsepower, data = data, subset = index))
boot.fn(Auto, 1:392)
###
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
boot.fn(Auto, sample(392, 392, replace = T))
###
boot(Auto, boot.fn, 1000)
###
summary(lm(mpg ~ horsepower, data = Auto))$coef
###
boot.fn <- function(data, index)
coef(
lm(mpg ~ horsepower + I(horsepower^2),
data = data, subset = index)
)
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
summary(
lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
)$coef
###
# OLS is based on restrictive (in this case) assumptions
plot(mpg ~ horsepower)
par(mfrow=c(2,2))
plot(lm(mpg ~ horsepower, data = Auto))
tlmgr_install(
pkgs = "mathtools.sty"
)
tinytex::parse_install(
text = "! LaTeX Error: File `mathtools.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `ulem.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `dutchcal.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `arydshln.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `placeins.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `tablefootnote.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `xifthen.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `ifmtarg.sty' not found."
)
tinytex::parse_install(
text = "! Package pdftex.def Error: File `Image/Boxplot_DE.png' not found: using draft setting."
)
tinytex::parse_install(
text = "! LaTeX Error: File `Image/Mice_Data' not found."
)
install.packages("igraph")
tinytex::parse_install(
text = "! LaTeX Error: File `size9.clo' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `relsize.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `soul.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `beamerthememetropolis.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `pgfopts.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `type1cm.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `algorithm.sty' not found."
)
tinytex::parse_install(
text = "! LaTeX Error: File `algpseudocode.sty' not found."
)
tinytex::parse_install(
text = "LaTeX Font Warning: Font shape `U/rsfs/m/n' in size <8.5> not available"
)
tinytex::parse_install(
text = "! LaTeX Font Warning: Font shape `U/rsfs/m/n' in size <8.5> not available"
)
## Clear the workspace
rm(list = ls())
library(rstudioapi)
## Clear the workspace
rm(list = ls())
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("functions.R")
library("TruncatedNormal")
library("EPGLM")
## Clear the workspace
rm(list = ls())
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("functions.R")
library("TruncatedNormal")
library("EPGLM")
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix()
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(nc[1:c]))
b = sum(nc[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(nc[c+1]*dim, mu[c], sigma[c])
c_truth[a:b, 1] = rep(c, nc[c+1])
}
return(list(y = y$V1, c_truth = c_truth))
}
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
y           = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix()
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:c]))
b = sum(freq[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(freq[c+1]*dim, mu[c], sigma[c])
c_truth[a:b, 1] = rep(c, freq[c+1])
}
return(list(y = y$V1, c_truth = c_truth))
}
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
y           = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
y  = matrix()
Kn = length(freq)
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
freq  = freq_truth
dim   = J
mu    = mu_truth
sigma = sigma_truth
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:c]))
b = sum(freq[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(freq[c+1]*dim, mu[c], sigma[c])
c_truth[a:b, 1] = rep(c, freq[c+1])
}
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:c]))
b = sum(freq[1:(c+1)]) - 1
y[a:b, 1:dim] = rnorm(freq[c+1]*dim, mu[c], sigma[c])
c_truth[a:b]  = c
}
return(list(y = y, c_truth = c_truth))
}
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
y           = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
data        = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
# Simulation study multivariate ------------------------------------------------------------
set.seed(0)
# Simulate the data from multivariate spherical Gaussian mixture
freq_truth  = c(59, 71, 48)
n           = sum(freq_truth)    # sample size
Kn_truth    = length(freq_truth) # true number of components
mu_truth    = c(-4, 0, 4)        # true means
sigma_truth = rep(1, Kn_truth)   # true sigma
J           = 13
data        = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
y           = data$y - mean(data$y) # center the data
y           = scale(y)              # scale the data
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:(c-1)]))
b = sum(freq[1:c]) - 1
y[a:b, 1:dim] = rnorm(freq[c]*dim, mu[c], sigma[c])
c_truth[a:b]  = c
}
return(list(y = y, c_truth = c_truth))
}
data        = simdat_mult(freq  = freq_truth,
dim   = J,
mu    = mu_truth,
sigma = sigma_truth)
# sim data from spherical multivariate normal clusters
simdat_mult <- function(freq, dim=1, mu = c(-4, 0, 4), sigma = rep(1,3)){
y  = matrix(nrow=n, ncol=J)
Kn = length(freq)
c_truth = double()
for(c in 1:Kn){
a = sum(c(freq[1:(c-1)]))
b = sum(freq[1:c]) - 1
y[a:b, 1:dim] = rnorm(freq[c]*dim, mu[c], sigma[c])
c_truth[a:b]  = c
}
return(list(y = y, c_truth = c_truth))
}
# CARICAMENTO PACCHETTI ---------------------------------------------------
library("exams");library("rmarkdown");library("base64enc");library("tinytex")
# Code to set the working directory to the current folder from RStudio
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# SETTAGGIO DIRECTORIES ----------------------------------------
gen_dir <- getwd()
#"/Users/Ruggiero/Dropbox/Dipartimento/Statistica/-R_exams"
cur_dir <- paste0(gen_dir,"/2023-05-11_eng")
# scelta sotto gruppi di esercizi
ex1_pool <- rbind(c("indicibaseEx1_1.Rmd","indicibaseEx1_2.Rmd","indicibaseEx1_3.Rmd","indicibaseEx1_4.Rmd"),
c("indicibaseEx2_1.Rmd","indicibaseEx2_2.Rmd","indicibaseEx2_3.Rmd","indicibaseEx2_4.Rmd"),
c("indicibaseEx3_1.Rmd","indicibaseEx3_2.Rmd","indicibaseEx3_3.Rmd","indicibaseEx3_4.Rmd"))
ex2_pool <- rbind("indici_av_Ex1.Rmd","indici_av_Ex2.Rmd")
ex3_pool <- rbind("graphics_bxp.Rmd","graphics_scp.Rmd")
ex4_pool <- rbind(c("cheb_reg_emp_1.Rmd","cheb_reg_emp_2.Rmd"),
c("Cov_Corr_1.Rmd","Cov_Corr_2.Rmd"))
#  c("regressione_1.Rmd","regressione_2.Rmd"))
ex5_pool <- rbind(c("prob_baseEx1_1.Rmd","prob_baseEx1_2.Rmd","prob_baseEx1_3.Rmd","prob_baseEx1_4.Rmd"),
c("prob_baseEx2_1.Rmd","prob_baseEx2_2.Rmd","prob_baseEx2_3.Rmd","prob_baseEx2_4.Rmd"))
ex6_pool <- rbind(c("Bayes_Ex1_1.Rmd","Bayes_Ex1_2.Rmd","Bayes_Ex1_3.Rmd"),
c("Bayes_Ex2_1.Rmd","Bayes_Ex2_2.Rmd","Bayes_Ex2_3.Rmd"))
ex7_pool <- rbind(c("binomialEx1_1.Rmd","binomialEx1_2.Rmd","binomialEx1_3.Rmd"),
c("binomialEx2_1.Rmd","binomialEx2_2.Rmd","binomialEx2_3.Rmd"),
c("binomialEx3_1.Rmd","binomialEx3_2.Rmd","binomialEx3_3.Rmd"))
ex8_pool <- rbind(c("poissonEx1_1.Rmd","poissonEx1_2.Rmd","poissonEx1_3.Rmd"),
c("poissonEx2_1.Rmd","poissonEx2_2.Rmd","poissonEx2_3.Rmd"),
c("exponentialEx1_1.Rmd","exponentialEx1_2.Rmd","exponentialEx1_3.Rmd"))
ex9_pool <- rbind(c("normalEx1_1.Rmd","normalEx1_2.Rmd","normalEx1_3.Rmd"),
c("normalEx2_1.Rmd","normalEx2_2.Rmd","normalEx2_3.Rmd"),
c("normalEx3_1.Rmd","normalEx3_2.Rmd","normalEx3_3.Rmd"))
ex10_pool <- rbind(c("confintnormEx1_1.Rmd","confintnormEx1_2.Rmd","confintnormEx1_3.Rmd"),
c("confintnormEx2_1.Rmd","confintnormEx2_2.Rmd","confintnormEx2_3.Rmd"),
c("confintEx1_1.Rmd","confintEx1_2.Rmd","confintEx1_3.Rmd"),
c("confintEx2_1.Rmd","confintEx2_2.Rmd","confintEx2_3.Rmd"))
ex11_pool <- rbind(c("tstatEx1_1.Rmd","tstatEx1_2.Rmd","tstatEx1_3.Rmd"),
c("tstatEx2_1.Rmd","tstatEx2_2.Rmd","tstatEx2_3.Rmd"))
no_exams=2
ex1 <- ex1_pool[sample(1:nrow(ex1_pool), no_exams, replace = TRUE),]
ex2 <- ex2_pool[sample(1:nrow(ex2_pool), no_exams, replace = TRUE),]
ex3 <- ex3_pool[sample(1:nrow(ex3_pool), no_exams, replace = TRUE),]
ex4 <- ex4_pool[sample(1:nrow(ex4_pool), no_exams, replace = TRUE),]
ex5 <- ex5_pool[sample(1:nrow(ex5_pool), no_exams, replace = TRUE),]
ex6 <- ex6_pool[sample(1:nrow(ex6_pool), no_exams, replace = TRUE),]
ex7 <- ex7_pool[sample(1:nrow(ex7_pool), no_exams, replace = TRUE),]
ex8 <- ex8_pool[sample(1:nrow(ex8_pool), no_exams, replace = TRUE),]
ex9 <- ex9_pool[sample(1:nrow(ex9_pool), no_exams, replace = TRUE),]
ex10 <- ex10_pool[sample(1:nrow(ex10_pool), no_exams, replace = TRUE),]
ex11 <- ex11_pool[sample(1:nrow(ex11_pool), no_exams, replace = TRUE),]
# creazione esami singoli
myexam <- cbind(ex1,ex2,ex3,ex4,ex5,ex6,ex7,ex8,ex9,ex10,ex11)
# preferenze locali
# usa file intest_esame.dcf per modificare intestazione
# reglength = 6 funziona con Development Version, vedi http://www.r-exams.org/resources/
# usa envir = .GlobalEnv per usare dati generati da altri esercizi
varie <- "\\setlength{\\columnsep}{.2cm}\\setlength{\\oddsidemargin}{-6mm}\\setlength{\\hoffset}{-22mm}\\setlength{\\textwidth}{20.5cm}\\newenvironment{answerlist1}{\\vspace*{-3mm}\\renewcommand{\\labelenumii}{(\\alph{enumii})}\\begin{enumerate}\\itemsep0mm\\itemindent-2mm}{\\end{enumerate}} \\renewenvironment{answerlist}{\\vspace*{-3mm}\\renewcommand{\\labelenumii}{(\\alph{enumii})}\\begin{multicols}{5}\\begin{enumerate}\\itemsep0mm\\itemindent-2mm}{\\end{enumerate}\\end{multicols}\\vspace*{0mm}}
\\newenvironment{answerlist3}{\\vspace*{-3mm}\\renewcommand{\\labelenumii}{(\\alph{enumii})}\\begin{multicols}{3}\\begin{enumerate}\\itemsep0mm\\itemindent-2mm}{\\end{enumerate}\\end{multicols}\\vspace*{0mm}}"
# risposte su colonna singola
answerlist1 <- function(..., sep = ". ", markup = c("markdown","latex")){if (match.arg(markup) == "latex") {
writeLines(c("\\begin{answerlist1}", paste("  \\item", do.call("paste", list(..., sep = sep))), "\\end{answerlist1}"))} else {writeLines(c("Answerlist", "----------", paste("*", do.call("paste", list(..., sep = sep)))))}}
# risposte su 3 colonne
answerlist3 <- function(..., sep = ". ", markup = c("markdown","latex")){if (match.arg(markup) == "latex") {
writeLines(c("\\begin{answerlist3}", paste("  \\item", do.call("paste", list(..., sep = sep))), "\\end{answerlist3}"))} else {writeLines(c("Answerlist", "----------", paste("*", do.call("paste", list(..., sep = sep)))))}}
# generazione pdf
setwd(cur_dir)
exam_date <- "2023-05-11"
ex_dir <- "../ex_ENG"
intest <- "../intest_esame_ENG.dcf"
set.seed(500);exams2nops(myexam, n=no_exams,
date = exam_date, language = intest,
institution = "SME - Università di Torino", logo = paste0(gen_dir,"/logoUniTo.png"),
title = "Statistics Exam", intro = "For each question, mark the correct answer on the answer sheet. If not otherwise specified, there is only one correct answer.",
dir = "pdf",
edir = ex_dir,
name = paste(exam_date,"-",sep = ""),
envir = .GlobalEnv, verbose = F, duplex = FALSE,
blank = 0,
twocolumn = T, header = varie,
# Per Giovanni: prende tavole in inglese da DropBox
pages = paste0(gen_dir,"/tavole3b_eng.pdf"),
# Per Matteo: prende tavole da locale perché R dà errore altrimenti
# pages = "/Users/matteogiordano/Desktop/tavole3b_eng.pdf",
reglength = 7)
# generate solutions pdfs
answerlist1 <- answerlist; answerlist3 <- answerlist;
set.seed(500); exams2pdf(myexam,
name = paste(exam_date,"-sol-",sep = ""),
dir = "soluz",
edir = "../ex_ENG",
# verbose = F,
# control = list(cloze.collapse = "enumerate"),
# header = varie,
# template = "/Users/Ruggiero/R_exams/exam.tex",
envir = .GlobalEnv,template = "solution"
)
source("C:/Users/39339/Dropbox/GitHub/GARP/GARP_extra.R", echo=TRUE)
